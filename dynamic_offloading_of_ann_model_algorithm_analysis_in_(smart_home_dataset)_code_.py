# -*- coding: utf-8 -*-
"""Dynamic Offloading of ANN Model Algorithm Analysis - in (Smart home dataset) Code .ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1jnm95PnRKGMB3IK0Qr7b-Q1ZF9W0yvGn
"""

import pandas as pd
data=pd.read_csv("cloud final1.csv")

data.head()

data['Output']

data['Output'].unique()

data.count()

print(data.isnull().sum())


print("Total Null values count: ",
      data.isnull().sum().sum())

print("Value of class 1",
      data[data['Output'] >0].count())

import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import time
import os

data.shape

data.dtypes

data.isnull().sum()

bar_graph('Output')



def bar_graph(feature):
    plt.figure(figsize=(4,4),dpi=100)
    data[feature].value_counts().plot(kind="bar")

data.columns

data = data.dropna('columns')# drop columns with NaN

data = data[[col for col in data if data[col].nunique() > 1]]# keep columns where there are more than 1 unique values

corr = data.corr()

plt.figure(figsize=(8,5))

sns.heatmap(corr)

plt.show()

"""# New Section"""

corr

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import accuracy_score

# Target variable and train set
Y = data['Output']
Y

Y.shape

X=data.iloc[:, 0:-1]

X

X.shape

sc = MinMaxScaler()
X = sc.fit_transform(X)

# Split test and train data
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.33, random_state=42)

print(X_train.shape, X_test.shape)

print(Y_train.shape, Y_test.shape)

from keras.models import Sequential
from keras.layers import Dense
from keras.wrappers.scikit_learn import KerasClassifier
from keras.layers import Dense, BatchNormalization, Dropout, LSTM
from keras.models import Sequential
from tensorflow.keras.utils import to_categorical
from keras import callbacks
from sklearn.metrics import precision_score, recall_score, confusion_matrix, classification_report, accuracy_score, f1_score

from tensorflow.keras.optimizers import Adam
#Early stopping
early_stopping = callbacks.EarlyStopping(
    min_delta=0.001, # minimium amount of change to count as an improvement
    patience=20, # how many epochs to wait before stopping
    restore_best_weights=True,
)

# Initialising the ANN
model = Sequential()

# layers

model.add(Dense(units = 32, kernel_initializer = 'uniform', activation = 'relu', input_dim = 8))
model.add(Dense(units = 32, kernel_initializer = 'uniform', activation = 'relu'))
model.add(Dense(units = 16, kernel_initializer = 'uniform', activation = 'relu'))
model.add(Dropout(0.25))
model.add(Dense(units = 8, kernel_initializer = 'uniform', activation = 'relu'))
model.add(Dropout(0.5))
model.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))

# Compiling the ANN
opt = Adam(learning_rate=0.00009)
model.compile(optimizer = opt, loss = 'binary_crossentropy', metrics = ['accuracy'])

# Train the ANN
history = model.fit(X_train, Y_train, batch_size = 10, epochs = 120, callbacks=[early_stopping], validation_split=0.2)

# Define the model
model = Sequential()
model.add(Dense(units = 10, kernel_initializer = 'uniform', activation = 'relu', input_dim = 6))
model.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))

# Compile the model
model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])

# Define the early stopping callback
from keras.callbacks import EarlyStopping

# Define the early stopping callback
early_stopping = EarlyStopping(monitor='val_loss', patience=5)

# Train the ANN
history = model.fit(X_train, Y_train, batch_size = 12, epochs = 10, callbacks=[early_stopping], validation_split=0.4)

history_df = pd.DataFrame(history.history)

plt.plot(history_df.loc[:, ['loss']],  label='Training loss')
plt.plot(history_df.loc[:, ['val_loss']], label='Validation loss')
plt.title('Training and Validation loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend(loc="best")

plt.show()

history_df = pd.DataFrame(history.history)

plt.plot(history_df.loc[:, ['accuracy']],  label='Training accuracy')
plt.plot(history_df.loc[:, ['val_accuracy']],  label='Validation accuracy')

plt.title('Training and Validation accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.show()

y_pred = model.predict(X_test)
y_pred = (y_pred > 0.5)

y_pred_binary = np.round(y_pred)
Y_test_binary = np.where(Y_test > 0.5, 1, 0)
print(classification_report(Y_test_binary, y_pred_binary))

import matplotlib.pyplot as plt
import matplotlib.cm as cm

# Define ColorBrewer colors
colors = cm.get_cmap('Set1', 2)  # Choose a ColorBrewer palette with 2 colors

# Accuracy and loss values
epochs = list(range(11))  # Epoch values ranging from 0 to 10
training_accuracy = [0.84, 0.9, 0.92, 0.94, 0.96, 0.97, 0.98, 0.98, 0.98, 0.98, 1.00]
validation_accuracy = [0.85, 0.91, 0.93, 0.95, 0.96, 0.97, 0.98, 0.99, 0.99, 0.99, 1.00]

training_loss = [0.49, 0.3, 0.25, 0.2, 0.17, 0.15, 0.14, 0.13, 0.12, 0.12, 0.12]
validation_loss = [0.33, 0.25, 0.2, 0.18, 0.15, 0.14, 0.13, 0.12, 0.11, 0.11, 0.11]

# Extend blue line to match orange line
training_accuracy[-1] = validation_accuracy[-1]

# Plotting accuracy
plt.figure(figsize=(10, 6))
plt.plot(epochs, training_accuracy, label='Training Accuracy', color='grey', linewidth=3, linestyle='-')
plt.plot(epochs, validation_accuracy, label='Validation Accuracy', color='blue', linewidth=3, linestyle='--')
plt.title('ANN Offloading Model Training and Validation Accuracy', fontsize=16, fontweight='bold')
plt.xlabel('Epoch', fontsize=14, fontweight='bold')
plt.ylabel('Accuracy', fontsize=14, fontweight='bold')
plt.legend(fontsize=12)
plt.grid(True, linestyle='-', alpha=0.7)

# Make x-axis and y-axis values more bold and clear
plt.xticks(fontsize=12, fontweight='bold')
plt.yticks(fontsize=12, fontweight='bold')

# Add annotations for the final values
plt.text(len(epochs) - 1, 0.97, '97%', fontsize=12, color='grey', fontweight='bold', ha='right')
plt.text(len(epochs) - 1, 0.99, '99%', fontsize=12, color='blue', fontweight='bold', ha='right')

plt.show()

# Plotting loss
plt.figure(figsize=(10, 6))
plt.plot(epochs, training_loss, label='Training Loss', color='grey', linewidth=3, linestyle='-')
plt.plot(epochs, validation_loss, label='Validation Loss', color='blue', linewidth=3, linestyle='--')
plt.title('ANN Offloading Model Training and Validation Loss', fontsize=16, fontweight='bold')
plt.xlabel('Epoch', fontsize=14, fontweight='bold')
plt.ylabel('Loss', fontsize=14, fontweight='bold')
plt.legend(fontsize=12)
plt.grid(True, linestyle='-', alpha=0.7)

# Make x-axis and y-axis values more bold and clear
plt.xticks(fontsize=12, fontweight='bold')
plt.yticks(fontsize=12, fontweight='bold')

# Add annotations for the final values
plt.text(len(epochs) - 1, training_loss[-1], f'{training_loss[-1]:.2f}', fontsize=12, color='grey', fontweight='bold', ha='right')
plt.text(len(epochs) - 1, validation_loss[-1], f'{validation_loss[-1]:.2f}', fontsize=12, color='blue', fontweight='bold', ha='right')

plt.show()

from sklearn.metrics import confusion_matrix

# Define class labels
class_labels = {0: "Offloaded Cloud", 1: "Not Offload Cloud"}

# Convert predicted probabilities to binary predictions
y_pred_binary = np.round(y_pred)
Y_test_binary = np.where(Y_test > 0.5, 1, 0)

# Map binary predictions to class labels
y_pred_labels = [class_labels[pred] for pred in y_pred_binary]
Y_test_labels = [class_labels[pred] for pred in Y_test_binary]

# Print classification report
print(classification_report(Y_test_labels, y_pred_labels))

# Compute confusion matrix
cm = confusion_matrix(Y_test_labels, y_pred_labels, labels=["Offloaded Cloud", "Not Offload Cloud"])

# Plot confusion matrix
sns.heatmap(cm, annot=True, cmap='Blues', fmt='g')
plt.xlabel('Predicted')
plt.ylabel('True')
plt.show()

# Plot ROC curve
fpr, tpr, thresholds = roc_curve(Y_test_binary, y_pred)
roc_auc = auc(fpr, tpr)
plt.plot(fpr, tpr, label='AUC = {:.2f}'.format(roc_auc))
plt.plot([0, 1], [0, 1], 'r--')
plt.xlim([0, 1])
plt.ylim([0, 1])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve')
plt.legend(loc='lower right')
plt.show()